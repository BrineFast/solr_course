{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce986092-15d7-47d3-992e-2112c6b49e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411ece2-7644-43c6-ac42-99f8b813d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_hash(word):\n",
    "    res = set()\n",
    "    for i in word.lower().split():\n",
    "        for k in range(0, len(i) - 3, 3):\n",
    "            res.add(tuple([i[k:k+3], i[k+1:k+4], i[k+2:k+5]]))\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6146e4-72fd-493f-a21a-4b3651ff7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_hash(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70251b66-3bad-435a-81d8-cc8dcda10900",
   "metadata": {},
   "outputs": [],
   "source": [
    "train: pd.DataFrame = pd.merge(pd.read_csv(\"data/train.csv\", encoding = \"ISO-8859-1\"), pd.read_csv(\"data/product_descriptions.csv\", encoding = \"ISO-8859-1\"), on=\"product_uid\")\n",
    "test: pd.DataFrame = pd.merge(pd.read_csv(\"data/test.csv\", encoding = \"ISO-8859-1\"), pd.read_csv(\"data/product_descriptions.csv\", encoding = \"ISO-8859-1\"), on=\"product_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e4e9a-2df8-4b69-86be-7f61dc4972a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"search_term\"] == \"angle bracket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077afd85-56a4-4dfa-8afd-3f9502748fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train[\"search_term\"].unique()\n",
    "features = {}\n",
    "batch_size = 1024\n",
    "trigram_dimension = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf3118-44b6-4fb6-90f0-bd6d54423ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    for j in train[train[\"search_term\"] == i].iterrows():\n",
    "        document = word_hash(f\"{j[1][2]} {j[1][5]}\")\n",
    "        if j[1][3] not in features:\n",
    "            features[word_hash(j[1][3])] = {\"positive\": [], \"negative\": []}            \n",
    "        elif j[1][4] < 2:\n",
    "            features[word_hash(j[1][3])][\"negative\"].append(document)\n",
    "        else:\n",
    "            features[word_hash(j[1][3])][\"positive\"].append(document)\n",
    "        for f in features:\n",
    "            if f != word_hash(j[1][3]) and len(features[f][\"negative\"]) < 4 and document not in features[f][\"positive\"] and document not in features[f][\"negative\"]:\n",
    "                features[f][\"negative\"].append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53df058-2e37-408b-b9cb-d138ff4f45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/features.npy\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc521222-ce58-4c0a-8cd3-beb1ff22a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSSM, self).__init__()\n",
    "        assert (trigram_dimension == 30000)\n",
    "        self.l1 = nn.Linear(trigram_dimension, 300)\n",
    "        nn.init.xavier_uniform_(self.l1.weight)\n",
    "        self.l2 = nn.Linear(300, 300)\n",
    "        nn.init.xavier_uniform_(self.l2.weight)\n",
    "        self.l3 = nn.Linear(300, 128)\n",
    "        nn.init.xavier_uniform_(self.l3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = F.tanh(self.l3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d7595-3f64-4566-8354-e8f45f6a4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DSSM().to(\"cuda\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720b067-f860-4866-8f92-38446a5bd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, epoch=5):\n",
    "    for e_idx in range(epoch):\n",
    "        batch_idx = 0\n",
    "        negative = []\n",
    "        for feature in features:\n",
    "            negative = features[feature][\"negative\"]\n",
    "            for positive in features[feature][\"positive\"]:\n",
    "                # size: (batch_size, 128)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out_q = model(Tensor(feature))\n",
    "                out_p = model(Tensor(positive))\n",
    "                out_n1 = model(Tensor(negative[0]))\n",
    "                out_n2 = model(Tensor(negative[1]))\n",
    "                out_n3 = model(Tensor(negative[2]))\n",
    "                out_n4 = model(Tensor(negative[3]))\n",
    "\n",
    "                # # Relevance measured by cosine similarity\n",
    "                # size: (batch_size)\n",
    "                cos_qp = torch.cosine_similarity(out_q, out_p, dim=1)\n",
    "                cos_qn1 = torch.cosine_similarity(out_q, out_n1, dim=1)\n",
    "                cos_qn2 = torch.cosine_similarity(out_q, out_n2, dim=1)\n",
    "                cos_qn3 = torch.cosine_similarity(out_q, out_n3, dim=1)\n",
    "                cos_qn4 = torch.cosine_similarity(out_q, out_n4, dim=1)\n",
    "                cos_uni = torch.cat((cos_qp, cos_qn1, cos_qn2, cos_qn3, cos_qn4), 1)  # size: (batch_size,5)\n",
    "\n",
    "                # # posterior probability computed by softmax\n",
    "                softmax_qp = F.softmax(cos_uni, dim=1)[:, 0]  # size: (batch_size)\n",
    "                loss = -torch.log(torch.prod(softmax_qp))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_idx += 1\n",
    "\n",
    "def predict(data, model):\n",
    "    return [model(q, f\"{r} {d}\") for q, r, d in data][0].data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bb333-9890-45a2-b9cb-f3a136472cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(\"data/features.npy\", \"r+\")\n",
    "train(features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f0be5-7a79-4c19-a5e8-3c4797c5042d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for row, predict in (test.iterrows(), predict(test, model)):\n",
    "    model.eval()\n",
    "    res[row[1][0]] = predict + 2\n",
    "    \n",
    "with open('submission.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, res.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
